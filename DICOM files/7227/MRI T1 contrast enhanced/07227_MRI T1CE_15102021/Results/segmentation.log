[INFO     | inferer         | L191  ] | 2024-08-03T17:50:45+0300: Infer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=False, sliding_window_batch_size=4, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>) and device: cpu
[INFO     | data            | L138  ] | 2024-08-03T17:50:45+0300: Successfully validated input images (received 1). Input mode: DataMode.NIFTI_FILE
[INFO     | data            | L160  ] | 2024-08-03T17:50:45+0300: Received files: T1: False, T1C: True, T2: False, FLAIR: False
[INFO     | data            | L169  ] | 2024-08-03T17:50:45+0300: Inference mode: InferenceMode.T1C_O
[INFO     | model           | L55   ] | 2024-08-03T17:50:45+0300: No loaded compatible model found (Switching from None to InferenceMode.T1C_O). Loading Model and weights...
[ERROR    | inferer         | L82   ] | 2024-08-03T17:50:45+0300: Traceback (most recent call last):
  File "/home/eliyams/Downloads/FinalProject/linux/segmentation/main_segmentation.py", line 25, in <module>
    f = segment(path)
        ^^^^^^^^^^^^^
  File "/home/eliyams/Downloads/FinalProject/linux/segmentation/main_segmentation.py", line 19, in segment
    _ = inferer.infer(
        ^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/utils/console_decorators.py", line 22, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/inferer.py", line 201, in infer
    self.model_handler.load_model(
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/model.py", line 59, in load_model
    self.model = self._load_model(num_input_modalities=num_input_modalities)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/model.py", line 88, in _load_model
    raise NotImplementedError(
NotImplementedError: No weights found for model InferenceMode.T1C_O and selection ModelSelection.BEST. 
Available models: ['t1-t1c-t2-fla', 't1-t1c-fla', 't1-t1c', 't1c-fla', 't1c-o', 'fla-o', 't1-o']

[INFO     | inferer         | L191  ] | 2024-08-03T21:10:46+0300: Infer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=False, sliding_window_batch_size=4, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>) and device: cpu
[INFO     | data            | L138  ] | 2024-08-03T21:10:46+0300: Successfully validated input images (received 1). Input mode: DataMode.NIFTI_FILE
[INFO     | data            | L160  ] | 2024-08-03T21:10:46+0300: Received files: T1: False, T1C: True, T2: False, FLAIR: False
[INFO     | data            | L169  ] | 2024-08-03T21:10:46+0300: Inference mode: InferenceMode.T1C_O
[INFO     | model           | L55   ] | 2024-08-03T21:10:46+0300: No loaded compatible model found (Switching from None to InferenceMode.T1C_O). Loading Model and weights...
[ERROR    | inferer         | L82   ] | 2024-08-03T21:10:46+0300: Traceback (most recent call last):
  File "/home/eliyams/Downloads/FinalProject/linux/segmentation/main_segmentation.py", line 25, in <module>
    f = segment(path)
        ^^^^^^^^^^^^^
  File "/home/eliyams/Downloads/FinalProject/linux/segmentation/main_segmentation.py", line 19, in segment
    _ = inferer.infer(
        ^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/utils/console_decorators.py", line 22, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/inferer.py", line 201, in infer
    self.model_handler.load_model(
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/model.py", line 59, in load_model
    self.model = self._load_model(num_input_modalities=num_input_modalities)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/model.py", line 88, in _load_model
    raise NotImplementedError(
NotImplementedError: No weights found for model InferenceMode.T1C_O and selection ModelSelection.BEST. 
Available models: ['t1-t1c-t2-fla', 't1-t1c-fla', 't1-t1c', 't1c-fla', 't1c-o', 'fla-o', 't1-o']

[INFO     | inferer         | L191  ] | 2024-08-03T21:35:39+0300: Infer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=False, sliding_window_batch_size=4, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>) and device: cpu
[INFO     | data            | L138  ] | 2024-08-03T21:35:39+0300: Successfully validated input images (received 1). Input mode: DataMode.NIFTI_FILE
[INFO     | data            | L160  ] | 2024-08-03T21:35:39+0300: Received files: T1: False, T1C: True, T2: False, FLAIR: False
[INFO     | data            | L169  ] | 2024-08-03T21:35:39+0300: Inference mode: InferenceMode.T1C_O
[INFO     | model           | L55   ] | 2024-08-03T21:35:39+0300: No loaded compatible model found (Switching from None to InferenceMode.T1C_O). Loading Model and weights...
[ERROR    | inferer         | L82   ] | 2024-08-03T21:35:39+0300: Traceback (most recent call last):
  File "/home/eliyams/Downloads/FinalProject/linux/segmentation/main_segmentation.py", line 25, in <module>
    f = segment(path)
        ^^^^^^^^^^^^^
  File "/home/eliyams/Downloads/FinalProject/linux/segmentation/main_segmentation.py", line 19, in segment
    _ = inferer.infer(
        ^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/utils/console_decorators.py", line 22, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/inferer.py", line 201, in infer
    self.model_handler.load_model(
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/model.py", line 59, in load_model
    self.model = self._load_model(num_input_modalities=num_input_modalities)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/model.py", line 89, in _load_model
    raise NotImplementedError(
NotImplementedError: No weights found for model InferenceMode.T1C_O and selection ModelSelection.BEST. 
Available models: ['t1-t1c-t2-fla', 't1-t1c-fla', 't1-t1c', 't1c-fla', 't1c-o', 'fla-o', 't1-o']

[INFO     | inferer         | L191  ] | 2024-08-03T21:36:59+0300: Infer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=False, sliding_window_batch_size=4, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>) and device: cpu
[INFO     | data            | L138  ] | 2024-08-03T21:36:59+0300: Successfully validated input images (received 1). Input mode: DataMode.NIFTI_FILE
[INFO     | data            | L160  ] | 2024-08-03T21:36:59+0300: Received files: T1: False, T1C: True, T2: False, FLAIR: False
[INFO     | data            | L169  ] | 2024-08-03T21:36:59+0300: Inference mode: InferenceMode.T1C_O
[INFO     | model           | L55   ] | 2024-08-03T21:36:59+0300: No loaded compatible model found (Switching from None to InferenceMode.T1C_O). Loading Model and weights...
[ERROR    | inferer         | L82   ] | 2024-08-03T21:36:59+0300: Traceback (most recent call last):
  File "/home/eliyams/Downloads/FinalProject/linux/segmentation/main_segmentation.py", line 25, in <module>
    f = segment(path)
        ^^^^^^^^^^^^^
  File "/home/eliyams/Downloads/FinalProject/linux/segmentation/main_segmentation.py", line 19, in segment
    _ = inferer.infer(
        ^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/utils/console_decorators.py", line 22, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/inferer.py", line 201, in infer
    self.model_handler.load_model(
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/model.py", line 59, in load_model
    self.model = self._load_model(num_input_modalities=num_input_modalities)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/eliyams/anaconda3/envs/env_final_project/lib/python3.11/site-packages/brainles_aurora/inferer/model.py", line 89, in _load_model
    raise NotImplementedError(
NotImplementedError: No weights found for model InferenceMode.T1C_O and selection ModelSelection.BEST. 
Available models: ['t1-t1c-t2-fla', 't1-t1c-fla', 't1-t1c', 't1c-fla', 't1c-o', 'fla-o', 't1-o']

[INFO     | inferer         | L191  ] | 2024-08-03T21:40:23+0300: Infer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=False, sliding_window_batch_size=4, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>) and device: cpu
[INFO     | data            | L138  ] | 2024-08-03T21:40:23+0300: Successfully validated input images (received 1). Input mode: DataMode.NIFTI_FILE
[INFO     | data            | L160  ] | 2024-08-03T21:40:23+0300: Received files: T1: False, T1C: True, T2: False, FLAIR: False
[INFO     | data            | L169  ] | 2024-08-03T21:40:23+0300: Inference mode: InferenceMode.T1C_O
[INFO     | model           | L58   ] | 2024-08-03T21:40:23+0300: No loaded compatible model found (Switching from None to InferenceMode.T1C_O). Loading Model and weights...
[INFO     | model           | L63   ] | 2024-08-03T21:40:23+0300: Successfully loaded model.
[INFO     | inferer         | L206  ] | 2024-08-03T21:40:23+0300: Setting up Dataloader
[INFO     | inferer         | L216  ] | 2024-08-03T21:40:23+0300: Running inference on device := cpu
[INFO     | model           | L206  ] | 2024-08-03T21:41:04+0300: Post-processing data
[INFO     | model           | L210  ] | 2024-08-03T21:41:04+0300: Returning post-processed data as Dict of Numpy arrays
[INFO     | inferer         | L218  ] | 2024-08-03T21:41:04+0300: Finished inference
[INFO     | inferer         | L222  ] | 2024-08-03T21:41:04+0300: Saving post-processed data as NIfTI files
[INFO     | data            | L263  ] | 2024-08-03T21:41:04+0300: Saved Output.SEGMENTATION to DICOM files/7227/MRI T1 contrast enhanced/07227_MRI T1CE_15102021/Results/segmentation.nii
[INFO     | data            | L263  ] | 2024-08-03T21:41:04+0300: Saved Output.METASTASIS_NETWORK to DICOM files/7227/MRI T1 contrast enhanced/07227_MRI T1CE_15102021/Results/mask.nii
[INFO     | inferer         | L226  ] | 2024-08-03T21:41:04+0300: ============================ Finished inference run ============================
[INFO     | inferer         | L191  ] | 2024-11-06T13:50:09+0200: Infer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=False, sliding_window_batch_size=4, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>) and device: cpu
[INFO     | data            | L138  ] | 2024-11-06T13:50:09+0200: Successfully validated input images (received 1). Input mode: DataMode.NIFTI_FILE
[INFO     | data            | L160  ] | 2024-11-06T13:50:09+0200: Received files: T1: False, T1C: True, T2: False, FLAIR: False
[INFO     | data            | L169  ] | 2024-11-06T13:50:09+0200: Inference mode: InferenceMode.T1C_O
[INFO     | model           | L58   ] | 2024-11-06T13:50:09+0200: No loaded compatible model found (Switching from None to InferenceMode.T1C_O). Loading Model and weights...
[INFO     | model           | L63   ] | 2024-11-06T13:50:10+0200: Successfully loaded model.
[INFO     | inferer         | L206  ] | 2024-11-06T13:50:10+0200: Setting up Dataloader
[INFO     | inferer         | L216  ] | 2024-11-06T13:50:10+0200: Running inference on device := cpu
[INFO     | model           | L206  ] | 2024-11-06T13:50:49+0200: Post-processing data
[INFO     | model           | L210  ] | 2024-11-06T13:50:49+0200: Returning post-processed data as Dict of Numpy arrays
[INFO     | inferer         | L218  ] | 2024-11-06T13:50:49+0200: Finished inference
[INFO     | inferer         | L222  ] | 2024-11-06T13:50:49+0200: Saving post-processed data as NIfTI files
[INFO     | data            | L263  ] | 2024-11-06T13:50:49+0200: Saved Output.SEGMENTATION to DICOM files/7227/MRI T1 contrast enhanced/07227_MRI T1CE_15102021/Results/segmentation.nii
[INFO     | data            | L263  ] | 2024-11-06T13:50:49+0200: Saved Output.METASTASIS_NETWORK to DICOM files/7227/MRI T1 contrast enhanced/07227_MRI T1CE_15102021/Results/mask.nii
[INFO     | inferer         | L226  ] | 2024-11-06T13:50:49+0200: ============================ Finished inference run ============================
[INFO     | inferer         | L191  ] | 2024-11-06T13:54:03+0200: Infer with config: AuroraInfererConfig(log_level=20, device=<Device.AUTO: 'auto'>, cuda_devices='0', tta=False, sliding_window_batch_size=4, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>) and device: cpu
[INFO     | data            | L138  ] | 2024-11-06T13:54:03+0200: Successfully validated input images (received 1). Input mode: DataMode.NIFTI_FILE
[INFO     | data            | L160  ] | 2024-11-06T13:54:03+0200: Received files: T1: False, T1C: True, T2: False, FLAIR: False
[INFO     | data            | L169  ] | 2024-11-06T13:54:03+0200: Inference mode: InferenceMode.T1C_O
[INFO     | model           | L58   ] | 2024-11-06T13:54:03+0200: No loaded compatible model found (Switching from None to InferenceMode.T1C_O). Loading Model and weights...
[INFO     | model           | L63   ] | 2024-11-06T13:54:03+0200: Successfully loaded model.
[INFO     | inferer         | L206  ] | 2024-11-06T13:54:03+0200: Setting up Dataloader
[INFO     | inferer         | L216  ] | 2024-11-06T13:54:03+0200: Running inference on device := cpu
[INFO     | model           | L206  ] | 2024-11-06T13:54:42+0200: Post-processing data
[INFO     | model           | L210  ] | 2024-11-06T13:54:42+0200: Returning post-processed data as Dict of Numpy arrays
[INFO     | inferer         | L218  ] | 2024-11-06T13:54:42+0200: Finished inference
[INFO     | inferer         | L222  ] | 2024-11-06T13:54:42+0200: Saving post-processed data as NIfTI files
[INFO     | data            | L263  ] | 2024-11-06T13:54:42+0200: Saved Output.SEGMENTATION to DICOM files/7227/MRI T1 contrast enhanced/07227_MRI T1CE_15102021/Results/segmentation.nii
[INFO     | data            | L263  ] | 2024-11-06T13:54:43+0200: Saved Output.METASTASIS_NETWORK to DICOM files/7227/MRI T1 contrast enhanced/07227_MRI T1CE_15102021/Results/mask.nii
[INFO     | inferer         | L226  ] | 2024-11-06T13:54:43+0200: ============================ Finished inference run ============================
